# Statistics Agent Team

[![Build Status][build-status-svg]][build-status-url]
[![Lint Status][lint-status-svg]][lint-status-url]
[![Go Report Card][goreport-svg]][goreport-url]
[![Docs][docs-godoc-svg]][docs-godoc-url]
[![License][license-svg]][license-url]

A multi-agent system for finding and verifying statistics from reputable web sources using Go, built with [Google ADK (Agent Development Kit)](https://github.com/google/adk-go) and [Eino](https://github.com/cloudwego/eino).

## Overview

This project implements a sophisticated multi-agent architecture that leverages LLMs and web search to find verifiable statistics, prioritizing well-known and respected publishers. The system ensures accuracy through automated verification of sources.

## Architecture

The system implements a **4-agent architecture** with clear separation of concerns:

> **Architecture**: Built with **Google ADK** for LLM-based operations. **Two orchestration options** available: ADK-based (LLM-driven decisions) and Eino-based (deterministic graph workflow). See [4_AGENT_ARCHITECTURE.md](4_AGENT_ARCHITECTURE.md) for complete details.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   User Request                          â”‚
â”‚              "Find climate change statistics"           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            ORCHESTRATION AGENT                          â”‚
â”‚              (Port 8000 - Both ADK/Eino)                â”‚
â”‚  â€¢ Coordinates 4-agent workflow                         â”‚
â”‚  â€¢ Manages retry logic                                  â”‚
â”‚  â€¢ Ensures quality standards                            â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚             â”‚                â”‚
      â–¼             â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RESEARCH  â”‚ â”‚SYNTHESIS â”‚ â”‚  VERIFICATION   â”‚
â”‚   AGENT    â”‚ â”‚  AGENT   â”‚ â”‚     AGENT       â”‚
â”‚ Port 8001  â”‚ â”‚Port 8004 â”‚ â”‚   Port 8002     â”‚
â”‚            â”‚ â”‚          â”‚ â”‚                 â”‚
â”‚ â€¢ Search   â”‚â”€â”‚â€¢ Fetch   â”‚â”€â”‚â€¢ Re-fetch URLs  â”‚
â”‚   Serper   â”‚ â”‚  URLs    â”‚ â”‚â€¢ Validate text  â”‚
â”‚ â€¢ Filter   â”‚ â”‚â€¢ LLM     â”‚ â”‚â€¢ Check numbers  â”‚
â”‚   Sources  â”‚ â”‚  Extract â”‚ â”‚â€¢ Flag errors    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚             â”‚                â”‚
      â–¼             â–¼                â–¼
  URLs only     Statistics     Verified Stats
```

### Agent Responsibilities

#### 1. Research Agent (`agents/research/`) - Web Search Only
- **No LLM required** - Pure search functionality
- Web search via Serper/SerpAPI integration
- Returns URLs with metadata (title, snippet, domain)
- Prioritizes reputable sources (`.gov`, `.edu`, research orgs)
- Output: List of `SearchResult` objects
- Port: **8001**

#### 2. Synthesis Agent (`agents/synthesis/`) - Google ADK â­ NEW
- **LLM-heavy** extraction agent
- Built with Google ADK and LLM (Gemini/Claude/OpenAI/Ollama)
- Fetches webpage content from URLs
- Extracts numerical statistics using LLM analysis
- Finds verbatim excerpts containing statistics
- Creates `CandidateStatistic` objects with proper metadata
- Port: **8004**

#### 3. Verification Agent (`agents/verification/`) - Google ADK
- **LLM-light** validation agent
- Re-fetches source URLs to verify content
- Checks excerpts exist verbatim in source
- Validates numerical values match exactly
- Flags hallucinations and discrepancies
- Returns verification results with pass/fail reasons
- Port: **8002**

#### 4a. Orchestration Agent - Google ADK (`agents/orchestration/`)
- Built with Google ADK for LLM-driven workflow decisions
- Coordinates: Research â†’ Synthesis â†’ Verification
- Implements adaptive retry logic
- Dynamic quality control
- Port: **8000**

#### 4b. Orchestration Agent - Eino (`agents/orchestration-eino/`) â­ RECOMMENDED
- **Deterministic graph-based workflow** (no LLM for orchestration)
- Type-safe orchestration with Eino framework
- Predictable, reproducible behavior
- Faster and lower cost
- Workflow: ValidateInput â†’ Research â†’ Synthesis â†’ Verification â†’ QualityCheck â†’ Format
- Port: **8000** (same port as ADK, but they don't run simultaneously)
- **Recommended for production use**

## Features

### Core Capabilities
- âœ… **Multi-agent pipeline** - Full verification workflow (Research â†’ Synthesis â†’ Verification) â­ **RECOMMENDED**
- âœ… **Real web search** - Google search via Serper/SerpAPI (30 URLs searched by default) ğŸ”
- âœ… **Comprehensive extraction** - Processes 15+ pages, reads 30K chars per page for thorough coverage
- âœ… **Source verification** - Validates excerpts and values match actual web pages
- âœ… **Human-in-the-loop retry** - Prompts user when partial results found
- âœ… **Reputable source prioritization** - Government, academic, research organizations

### Alternative Modes
- âœ… **Direct LLM mode** - Fast but uses LLM memory (âš ï¸ not recommended for statistics)
- âœ… **Hybrid mode** - LLM discovery + web verification (âš ï¸ low verification rate)
- âœ… **OpenAPI documentation** - Interactive Swagger UI for Direct agent (port 8005)

### Technical Stack
- âœ… **Multi-LLM providers** - Gemini, Claude, OpenAI, Ollama, xAI Grok via unified interface
- âœ… **Google ADK integration** - For LLM-based agents
- âœ… **Eino framework** - Deterministic graph orchestration â­ Recommended
- âœ… **A2A Protocol** - Agent-to-Agent interoperability (Google standard) ğŸ”—
- âœ… **LLM Observability** - ObservAI integration (Opik, Langfuse, Phoenix) ğŸ‘ï¸
- âœ… **Huma v2** - OpenAPI 3.1 docs for Direct agent
- âœ… **MCP Server** - Integration with Claude Code and other MCP clients
- âœ… **Docker deployment** - Easy containerized setup ğŸ³

## Output Format

The system returns verified statistics in JSON format:

```json
[
  {
    "name": "Global temperature increase since pre-industrial times",
    "value": 1.1,
    "unit": "Â°C",
    "source": "IPCC Sixth Assessment Report",
    "source_url": "https://www.ipcc.ch/...",
    "excerpt": "Global surface temperature has increased by approximately 1.1Â°C since pre-industrial times...",
    "verified": true,
    "date_found": "2025-12-13T10:30:00Z"
  }
]
```

### Field Descriptions

- **name**: Description of the statistic
- **value**: Numerical value (float32)
- **unit**: Unit of measurement (e.g., "Â°C", "%", "million", "billion")
- **source**: Name of source organization/publication
- **source_url**: URL to the original source
- **excerpt**: Verbatim quote containing the statistic
- **verified**: Whether the verification agent confirmed it
- **date_found**: Timestamp when statistic was found

## Installation

### Prerequisites

- Go 1.21 or higher
- LLM API key for your chosen provider:
  - **Gemini** (default): Google API key (set as `GOOGLE_API_KEY` or `GEMINI_API_KEY`)
  - **Claude**: Anthropic API key (set as `ANTHROPIC_API_KEY` or `CLAUDE_API_KEY`)
  - **OpenAI**: OpenAI API key (set as `OPENAI_API_KEY`)
  - **xAI Grok**: xAI API key (set as `XAI_API_KEY`)
  - **Ollama**: Local Ollama installation (default: `http://localhost:11434`)
- Optional: API keys for search provider (Google Search, etc.)

### Setup

1. Clone the repository:
```bash
git clone https://github.com/grokify/stats-agent.git
cd stats-agent
```

2. Install dependencies:
```bash
make install
# or
go mod download
```

3. Configure environment variables:
```bash
# For Gemini (default)
export GOOGLE_API_KEY="your-google-api-key"

# For Claude
export LLM_PROVIDER="claude"
export ANTHROPIC_API_KEY="your-anthropic-api-key"

# For OpenAI
export LLM_PROVIDER="openai"
export OPENAI_API_KEY="your-openai-api-key"

# For xAI Grok
export LLM_PROVIDER="xai"
export XAI_API_KEY="your-xai-api-key"

# For Ollama (local)
export LLM_PROVIDER="ollama"
export OLLAMA_URL="http://localhost:11434"
export LLM_MODEL="llama3:latest"

# Optional: Create .env file
cp .env.example .env
# Edit .env with your API keys
```

4. Build the agents:
```bash
make build
```

## Usage

You can run the system either with Docker (containerized) or locally. Choose the method that best fits your needs.

| Method | Best For | Command |
|--------|----------|---------|
| **Docker** ğŸ³ | Production, quick start, isolated environment | `docker-compose up -d` |
| **Local** ğŸ’» | Development, debugging, customization | `make run-all-eino` |

### Quick Start with Docker ğŸ³

The fastest way to get started:

```bash
# Start all agents with Docker Compose
docker-compose up -d

# Test the orchestration endpoint
curl -X POST http://localhost:8000/orchestrate \
  -H "Content-Type: application/json" \
  -d '{"topic": "climate change", "min_verified_stats": 5}'

# View logs
docker-compose logs -f

# Stop
docker-compose down
```

See [DOCKER.md](DOCKER.md) for complete Docker deployment guide.

---

### Local Development Setup

#### Running the Agents Locally

##### Option 1: Run all agents with Eino orchestrator (Recommended)
```bash
make run-all-eino
```

##### Option 2: Run all agents with ADK orchestrator
```bash
make run-all
```

##### Option 3: Run each agent separately (in different terminals)
```bash
# Terminal 1: Research Agent (ADK)
make run-research

# Terminal 2: Verification Agent (ADK)
make run-verification

# Terminal 3: Orchestration Agent (choose one)
make run-orchestration       # ADK version (LLM-based)
make run-orchestration-eino  # Eino version (deterministic, recommended)
```

#### Using the CLI

The CLI supports three modes: **Direct LLM search** (fast, like ChatGPT), **Direct + Verification** (hybrid), and **Multi-agent verification pipeline** (thorough, verified).

##### Direct Mode (âš ï¸ Not Recommended for Statistics)

Direct mode uses a single LLM call to find statistics from memory - similar to ChatGPT without web search:

```bash
# Start direct agent first
make run-direct

# Then query (fast but uses LLM memory)
./bin/stats-agent search "climate change" --direct
```

**Why Not Recommended for Statistics:**
- âŒ **Uses LLM memory** - Not real-time web search (training data up to Jan 2025)
- âŒ **Outdated URLs** - LLM guesses URLs where stats came from
- âŒ **Low accuracy** - Pages may have moved, changed, or be paywalled
- âš ï¸ **0% verification rate** - When combined with `--direct-verify`, most claims fail

**When to Use:**
- âœ… General knowledge questions
- âœ… Concept explanations
- âœ… Quick brainstorming (accept unverified data)

**For statistics, use Pipeline mode instead** (see below)

##### Hybrid Mode (âš ï¸ Also Not Recommended - Low Verification Rate)

Combines Direct mode with verification, but suffers from the same LLM memory issues:

```bash
# Start both agents
make run-direct-verify

# Then query
./bin/stats-agent search "climate change" --direct --direct-verify
```

**Why Not Recommended:**
- âŒ **Low verification rate** - Typically 0-30% of LLM claims verify
- âŒ **Same LLM memory problem** - URLs are guessed, not from real search
- âš ï¸ **Slow with poor results** - Verification overhead but few verified stats

**For reliable statistics, use Pipeline mode instead**

##### Multi-Agent Pipeline Mode (Thorough Verification)

For verified, web-scraped statistics (requires agents running):

```bash
# Start agents first
make run-all-eino

# Then in another terminal:
# Basic search with verification pipeline
./bin/stats-agent search "climate change"

# Request specific number of verified statistics
./bin/stats-agent search "global warming" --min-stats 15

# Increase candidate search space
./bin/stats-agent search "AI trends" --min-stats 10 --max-candidates 100

# Only reputable sources
./bin/stats-agent search "COVID-19 statistics" --reputable-only

# JSON output only
./bin/stats-agent search "renewable energy" --output json

# Text output only
./bin/stats-agent search "climate data" --output text
```

**Advantages of Multi-Agent Mode:**
- âœ… **Verified sources** - Actually fetches and checks web pages
- ğŸ” **Web search** - Finds current statistics from the web
- ğŸ¯ **Accuracy** - Validates excerpts and values match
- ğŸ”„ **Human-in-the-loop** - Prompts to continue if target not met

##### CLI Options

```bash
stats-agent search <topic> [options]

Options:
  -d, --direct              Use direct LLM search (fast, like ChatGPT)
      --direct-verify       Verify LLM claims with verification agent (requires --direct)
  -m, --min-stats <n>       Minimum statistics to find (default: 10)
  -c, --max-candidates <n>  Max candidates for pipeline mode (default: 50)
  -r, --reputable-only      Only use reputable sources
  -o, --output <format>     Output format: json, text, both (default: both)
      --orchestrator-url    Override orchestrator URL
  -v, --verbose             Show verbose debug information
      --version             Show version information
```

**Mode Comparison:**

| Mode | Speed | Accuracy | Agents Needed | Client Needs API Key? | Best For |
|------|-------|----------|---------------|----------------------|----------|
| `--direct` | âš¡âš¡âš¡ Fastest | âš ï¸ LLM-claimed | Direct agent only | âŒ No | Quick research, brainstorming |
| `--direct --direct-verify` | âš¡âš¡ Fast | âœ… Web-verified | Direct + Verification | âŒ No | Balanced speed + accuracy |
| Pipeline (default) | âš¡ Slower | âœ…âœ… Fully verified | All 4 agents | âŒ No | Maximum reliability |
```

---

### Using with Claude Code (MCP Server)

The system can be used as an MCP server with Claude Code and other MCP clients:

```bash
# Build the MCP server
make build-mcp

# Configure in Claude Code's MCP settings (see MCP_SERVER.md)
```

See [MCP_SERVER.md](MCP_SERVER.md) for detailed setup instructions.

### API Usage

You can also call the agents directly via HTTP (works with both Docker and local deployment):

```bash
# Call orchestration agent (port 8000 - supports both ADK and Eino)
curl -X POST http://localhost:8000/orchestrate \
  -H "Content-Type: application/json" \
  -d '{
    "topic": "climate change",
    "min_verified_stats": 10,
    "max_candidates": 30,
    "reputable_only": true
  }'
```

## Configuration

### Environment Variables

#### LLM Configuration

| Variable | Description | Default |
|----------|-------------|---------|
| `LLM_PROVIDER` | LLM provider: `gemini`, `claude`, `openai`, `xai`, `ollama` | `gemini` |
| `LLM_MODEL` | Model name (provider-specific) | See defaults below |
| `LLM_API_KEY` | Generic API key (overrides provider-specific) | - |
| `LLM_BASE_URL` | Base URL for custom endpoints (Ollama, etc.) | - |

**Provider-Specific API Keys:**
| Variable | Description | Default |
|----------|-------------|---------|
| `GOOGLE_API_KEY` / `GEMINI_API_KEY` | Google API key for Gemini | **Required for Gemini** |
| `ANTHROPIC_API_KEY` / `CLAUDE_API_KEY` | Anthropic API key for Claude | **Required for Claude** |
| `OPENAI_API_KEY` | OpenAI API key | **Required for OpenAI** |
| `XAI_API_KEY` | xAI API key for Grok | **Required for xAI** |
| `OLLAMA_URL` | Ollama server URL | `http://localhost:11434` |

**Default Models by Provider:**
- Gemini: `gemini-2.5-flash` (or `gemini-2.5-pro`)
- Claude: `claude-sonnet-4-20250514` (or `claude-opus-4-1-20250805`)
- OpenAI: `gpt-4o` (or `gpt-5`)
- xAI: `grok-4-1-fast-reasoning` (or `grok-4-1-fast-non-reasoning`)
- Ollama: `llama3:8b` (or `mistral:7b`)

See [LLM_CONFIGURATION.md](LLM_CONFIGURATION.md) for detailed LLM setup.

#### Search Configuration

| Variable | Description | Default |
|----------|-------------|---------|
| `SEARCH_PROVIDER` | Search provider: `serper`, `serpapi` | `serper` |
| `SERPER_API_KEY` | Serper API key (get from serper.dev) | Required for real search |
| `SERPAPI_API_KEY` | SerpAPI key (alternative provider) | Required for SerpAPI |

**Note:** Without a search API key, the research agent will use mock data. See [SEARCH_INTEGRATION.md](SEARCH_INTEGRATION.md) for setup details.

#### Observability Configuration

| Variable | Description | Default |
|----------|-------------|---------|
| `OBSERVABILITY_ENABLED` | Enable LLM observability | `false` |
| `OBSERVABILITY_PROVIDER` | Provider: `opik`, `langfuse`, `phoenix` | `opik` |
| `OBSERVABILITY_API_KEY` | API key for the provider | - |
| `OBSERVABILITY_ENDPOINT` | Custom endpoint (optional) | Provider default |
| `OBSERVABILITY_PROJECT` | Project name for grouping traces | `stats-agent-team` |

**Supported Providers:**
- [Comet Opik](https://www.comet.com/site/products/opik/) - LLM tracing and evaluation
- [Langfuse](https://langfuse.com/) - Open-source LLM observability
- [Arize Phoenix](https://phoenix.arize.com/) - ML observability platform

#### Other Configuration

| Variable | Description | Default |
|----------|-------------|---------|
| `RESEARCH_AGENT_URL` | Research agent URL | `http://localhost:8001` |
| `SYNTHESIS_AGENT_URL` | Synthesis agent URL | `http://localhost:8004` |
| `VERIFICATION_AGENT_URL` | Verification agent URL | `http://localhost:8002` |
| `ORCHESTRATOR_URL` | Orchestrator URL (both ADK/Eino) | `http://localhost:8000` |

### Port Configuration

Each agent exposes both HTTP and A2A (Agent-to-Agent) protocol endpoints:

| Agent | HTTP Port | A2A Port | Description |
|-------|-----------|----------|-------------|
| **Orchestration (ADK/Eino)** â­ | **8000** | **9000** | Graph-based workflow coordination |
| Research (ADK) | 8001 | 9001 | Web search via Serper/SerpAPI |
| Verification (ADK) | 8002 | 9002 | LLM-based verification |
| Synthesis (ADK) | 8004 | 9004 | LLM-based statistics extraction |
| **Direct (Huma)** â­ | **8005** | - | Direct LLM search with OpenAPI docs |

**A2A Endpoints per Agent:**
- `GET /.well-known/agent-card.json` - Agent discovery
- `POST /invoke` - JSON-RPC execution

Enable A2A with: `A2A_ENABLED=true`

## Project Structure

```
stats-agent/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ direct/             # Direct search agent (Huma + OpenAPI, port 8005) â­ NEW
â”‚   â”‚   â””â”€â”€ main.go
â”‚   â”œâ”€â”€ orchestration/      # Orchestration agent (Google ADK, port 8000)
â”‚   â”‚   â””â”€â”€ main.go
â”‚   â”œâ”€â”€ orchestration-eino/ # Orchestration agent (Eino, port 8000) â­
â”‚   â”‚   â””â”€â”€ main.go
â”‚   â”œâ”€â”€ research/           # Research agent (port 8001)
â”‚   â”‚   â””â”€â”€ main.go
â”‚   â”œâ”€â”€ synthesis/          # Synthesis agent (Google ADK, port 8004) â­
â”‚   â”‚   â””â”€â”€ main.go
â”‚   â””â”€â”€ verification/       # Verification agent (Google ADK, port 8002)
â”‚       â””â”€â”€ main.go
â”œâ”€â”€ pkg/
â”‚   â”œâ”€â”€ config/            # Configuration management
â”‚   â”œâ”€â”€ direct/            # Direct LLM search service
â”‚   â”œâ”€â”€ llm/               # Multi-provider LLM factory (FluxLLM + ObservAI)
â”‚   â”‚   â””â”€â”€ adapters/      # FluxLLM adapter for ADK integration
â”‚   â”œâ”€â”€ models/            # Shared data models
â”‚   â””â”€â”€ orchestration/     # Orchestration logic
â”œâ”€â”€ main.go                # CLI entry point
â”œâ”€â”€ Makefile              # Build and run commands
â”œâ”€â”€ go.mod                # Go dependencies
â”œâ”€â”€ .env.example          # Environment template
â””â”€â”€ README.md             # This file
```

## Development

### Building

```bash
make build
```

### Running Tests

```bash
make test
```

### Cleaning Build Artifacts

```bash
make clean
```

## Technology Stack

- **Language**: Go 1.21+
- **Agent Frameworks**:
  - [Google ADK (Agent Development Kit)](https://github.com/google/adk-go) - LLM-based agents + A2A protocol â­
  - [Eino](https://github.com/cloudwego/eino) - Deterministic graph orchestration â­
- **LLM Integration**:
  - [FluxLLM](https://github.com/grokify/fluxllm) - Multi-provider LLM abstraction
  - Supports: Gemini, Claude, OpenAI, xAI Grok, Ollama
- **Observability**:
  - [ObservAI](https://github.com/grokify/observai) - Unified LLM observability
  - Supports: Comet Opik, Langfuse, Arize Phoenix
- **Protocols**:
  - HTTP - Custom security, flexibility (ports 800x)
  - A2A - Agent-to-Agent interoperability (ports 900x)
- **Search**: Serper/SerpAPI via [MetaSerp](https://github.com/grokify/metaserp)

## How It Works

1. **User Request**: User provides a topic via CLI or API
2. **Orchestration**: Orchestrator receives request and initiates workflow
3. **Research Phase**: Research agent searches web for candidate statistics
4. **Verification Phase**: Verification agent validates each candidate
5. **Quality Control**: Orchestrator checks if minimum verified stats met
6. **Retry Logic**: If needed, request more candidates and verify
7. **Response**: Return verified statistics in structured JSON format

## Reputable Sources

The research agent prioritizes these source types:

- **Government Agencies**: CDC, NIH, Census Bureau, EPA, etc.
- **Academic Institutions**: Universities, research journals
- **Research Organizations**: Pew Research, Gallup, McKinsey, etc.
- **International Organizations**: WHO, UN, World Bank, IMF, etc.
- **Respected Media**: With proper citations (NYT, WSJ, Economist, etc.)

## Error Handling

- **Source Unreachable**: Marked as failed with reason
- **Excerpt Not Found**: Verification fails with explanation
- **Value Mismatch**: Flagged as discrepancy
- **Insufficient Results**: Automatic retry with more candidates
- **Max Retries Exceeded**: Returns partial results with warning

## Roadmap

See [ROADMAP.md](ROADMAP.md) for planned features including Perplexity integration, multi-language support, and browser extension.

## Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## Acknowledgments

- Built with [Google ADK (Agent Development Kit)](https://github.com/google/adk-go)
- Uses [Eino](https://github.com/cloudwego/eino) for deterministic orchestration
- Multi-LLM support via [FluxLLM](https://github.com/grokify/fluxllm)
- LLM observability via [ObservAI](https://github.com/grokify/observai)
- A2A protocol for agent interoperability
- Inspired by multi-agent collaboration frameworks

 [used-by-svg]: https://sourcegraph.com/github.com/grokify/stats-agent-team/-/badge.svg
 [used-by-url]: https://sourcegraph.com/github.com/grokify/stats-agent-team?badge
 [build-status-svg]: https://github.com/grokify/stats-agent-team/actions/workflows/ci.yaml/badge.svg?branch=main
 [build-status-url]: https://github.com/grokify/stats-agent-team/actions/workflows/ci.yaml
 [lint-status-svg]: https://github.com/grokify/stats-agent-team/actions/workflows/lint.yaml/badge.svg?branch=main
 [lint-status-url]: https://github.com/grokify/stats-agent-team/actions/workflows/lint.yaml
 [goreport-svg]: https://goreportcard.com/badge/github.com/grokify/stats-agent-team
 [goreport-url]: https://goreportcard.com/report/github.com/grokify/stats-agent-team
 [codeclimate-status-svg]: https://codeclimate.com/github/grokify/stats-agent-team/badges/gpa.svg
 [codeclimate-status-url]: https://codeclimate.com/github/grokify/stats-agent-team
 [docs-godoc-svg]: https://pkg.go.dev/badge/github.com/grokify/stats-agent-team
 [docs-godoc-url]: https://pkg.go.dev/github.com/grokify/stats-agent-team
 [loc-svg]: https://tokei.rs/b1/github/grokify/stats-agent-team
 [repo-url]: https://github.com/grokify/stats-agent-team
 [license-svg]: https://img.shields.io/badge/license-MIT-blue.svg
 [license-url]: https://github.com/grokify/stats-agent-team/blob/master/LICENSE
